{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBxotw/+w+x/rtvvwhBlMu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Walls182/LoginPersistenciabd/blob/main/TitanicKaggleClasificacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 1: Configuración inicial"
      ],
      "metadata": {
        "id": "VVJypaF3Flv8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fG-fqSF-FaUC"
      },
      "outputs": [],
      "source": [
        "# Importar librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Configuración de visualización\n",
        "plt.style.use('ggplot')\n",
        "sns.set_palette(\"Set2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 2: Cargar los datos"
      ],
      "metadata": {
        "id": "Yu93sU00Fvt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subir archivos a Colab\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Cargar los datasets\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "print(\"Forma del dataset de entrenamiento:\", train_df.shape)\n",
        "print(\"Forma del dataset de prueba:\", test_df.shape)\n",
        "print(\"\\nPrimeras 5 filas del train:\")\n",
        "print(train_df.head())"
      ],
      "metadata": {
        "id": "L3ScsrV2FhXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 3: Analisis Exploratorio de los Datos"
      ],
      "metadata": {
        "id": "CkFk5s_oF7ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Información básica del dataset\n",
        "print(\"Información del dataset de entrenamiento:\")\n",
        "print(train_df.info())\n",
        "print(\"\\nEstadísticas descriptivas:\")\n",
        "print(train_df.describe())\n",
        "\n",
        "# Valores faltantes\n",
        "print(\"\\nValores faltantes en train:\")\n",
        "print(train_df.isnull().sum())\n",
        "print(\"\\nValores faltantes en test:\")\n",
        "print(test_df.isnull().sum())\n",
        "\n",
        "# Distribución de la variable objetivo (Survived)\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Survived', data=train_df)\n",
        "plt.title('Distribución de Sobrevivientes (0 = No, 1 = Sí)')\n",
        "plt.show()\n",
        "\n",
        "# Sobrevivencia por género\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Survived', hue='Sex', data=train_df)\n",
        "plt.title('Sobrevivencia por Género')\n",
        "plt.show()\n",
        "\n",
        "# Sobrevivencia por clase\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Survived', hue='Pclass', data=train_df)\n",
        "plt.title('Sobrevivencia por Clase')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uei1T0QVGJGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 4: Preexploracion y procesamiento de los datos"
      ],
      "metadata": {
        "id": "fE0tph9uGQMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df):\n",
        "    # Crear una copia para no modificar el original\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # 1. Ingeniería de características - Extraer título del nombre\n",
        "    df_processed['Title'] = df_processed['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "\n",
        "    # Agrupar títulos poco comunes\n",
        "    title_mapping = {'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
        "                    'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare',\n",
        "                    'Mlle': 'Rare', 'Countess': 'Rare', 'Ms': 'Miss', 'Lady': 'Rare',\n",
        "                    'Jonkheer': 'Rare', 'Don': 'Rare', 'Dona': 'Rare', 'Mme': 'Rare',\n",
        "                    'Capt': 'Rare', 'Sir': 'Rare'}\n",
        "\n",
        "    df_processed['Title'] = df_processed['Title'].map(title_mapping)\n",
        "\n",
        "    # 2. Crear familia size\n",
        "    df_processed['FamilySize'] = df_processed['SibSp'] + df_processed['Parch'] + 1\n",
        "\n",
        "    # 3. Crear IsAlone\n",
        "    df_processed['IsAlone'] = 0\n",
        "    df_processed.loc[df_processed['FamilySize'] == 1, 'IsAlone'] = 1\n",
        "\n",
        "    # 4. Manejar valores faltantes en Age\n",
        "    age_imputer = SimpleImputer(strategy='median')\n",
        "    df_processed['Age'] = age_imputer.fit_transform(df_processed[['Age']])\n",
        "\n",
        "    # 5. Manejar valores faltantes en Fare (solo para test)\n",
        "    if 'Fare' in df_processed.columns:\n",
        "        fare_imputer = SimpleImputer(strategy='median')\n",
        "        df_processed['Fare'] = fare_imputer.fit_transform(df_processed[['Fare']])\n",
        "\n",
        "    # 6. Manejar valores faltantes en Embarked\n",
        "    df_processed['Embarked'].fillna(df_processed['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "    # 7. Codificar variables categóricas\n",
        "    label_encoder = LabelEncoder()\n",
        "    df_processed['Sex'] = label_encoder.fit_transform(df_processed['Sex'])\n",
        "    df_processed['Embarked'] = label_encoder.fit_transform(df_processed['Embarked'])\n",
        "    df_processed['Title'] = label_encoder.fit_transform(df_processed['Title'])\n",
        "\n",
        "    # 8. Eliminar columnas no necesarias\n",
        "    columns_to_drop = ['Name', 'Ticket', 'Cabin', 'PassengerId']\n",
        "    df_processed.drop([col for col in columns_to_drop if col in df_processed.columns],\n",
        "                     axis=1, inplace=True)\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# Aplicar preprocesamiento\n",
        "train_processed = preprocess_data(train_df)\n",
        "test_processed = preprocess_data(test_df)\n",
        "\n",
        "print(\"Train procesado:\")\n",
        "print(train_processed.head())"
      ],
      "metadata": {
        "id": "iycjY-04GaN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 5: Preparacion de los datos para el modelo"
      ],
      "metadata": {
        "id": "GBpms2TLGcm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar características y variable objetivo\n",
        "X = train_processed.drop('Survived', axis=1)\n",
        "y = train_processed['Survived']\n",
        "\n",
        "# Dividir en conjunto de entrenamiento y validación\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Normalizar características\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)"
      ],
      "metadata": {
        "id": "z8lm3jyDGoCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 6: Entrenamiento del modelo para clasificacion"
      ],
      "metadata": {
        "id": "21pUF_zaGpwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar Regresión Logística (apropiado para clasificación)\n",
        "model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Hacer predicciones\n",
        "y_pred = model.predict(X_val_scaled)\n",
        "y_pred_proba = model.predict_proba(X_val_scaled)[:, 1]  # Probabilidades para la clase 1\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f'Precisión del modelo: {accuracy:.4f}')\n",
        "print('\\nMatriz de confusión:')\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "print('\\nReporte de clasificación:')\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "id": "CFwUPSGIGwVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 7: Visualizacion de los resultados"
      ],
      "metadata": {
        "id": "ouXf_ZvUG2UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de confusión visual\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.ylabel('Verdadero')\n",
        "plt.xlabel('Predicho')\n",
        "\n",
        "# Importancia de características\n",
        "plt.subplot(1, 2, 2)\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': model.coef_[0]\n",
        "})\n",
        "feature_importance = feature_importance.sort_values('importance', ascending=True)\n",
        "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
        "plt.title('Importancia de Características')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wkruUznIG-Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 8: Prediccion del dataset de kaggle de titanic"
      ],
      "metadata": {
        "id": "RWe5bZNDHA00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparar datos de test\n",
        "X_test = test_processed\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Hacer predicciones\n",
        "test_predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Crear archivo de submission\n",
        "submission = pd.DataFrame({\n",
        "    'PassengerId': test_df['PassengerId'],\n",
        "    'Survived': test_predictions\n",
        "})\n",
        "\n",
        "# Guardar submission\n",
        "submission.to_csv('titanic_submission.csv', index=False)\n",
        "print(\"Archivo de submission creado: titanic_submission.csv\")\n",
        "\n",
        "# Descargar el archivo\n",
        "files.download('titanic_submission.csv')"
      ],
      "metadata": {
        "id": "S5r_c2pfHJSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 9: Hacer las predicciones individuales"
      ],
      "metadata": {
        "id": "rDg0cW-FHOvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predecir_sobrevivencia():\n",
        "    print(\"Ingrese los datos del pasajero:\")\n",
        "    pclass = int(input(\"Clase (1, 2, 3): \"))\n",
        "    sex = input(\"Sexo (male/female): \")\n",
        "    age = float(input(\"Edad: \"))\n",
        "    sibsp = int(input(\"Número de hermanos/esposos a bordo: \"))\n",
        "    parch = int(input(\"Número de padres/hijos a bordo: \"))\n",
        "    fare = float(input(\"Tarifa pagada: \"))\n",
        "    embarked = input(\"Puerto de embarque (C = Cherbourg, Q = Queenstown, S = Southampton): \")\n",
        "\n",
        "    # Crear DataFrame con los datos\n",
        "    passenger_data = pd.DataFrame({\n",
        "        'Pclass': [pclass],\n",
        "        'Sex': [1 if sex.lower() == 'female' else 0],  # Female=1, Male=0\n",
        "        'Age': [age],\n",
        "        'SibSp': [sibsp],\n",
        "        'Parch': [parch],\n",
        "        'Fare': [fare],\n",
        "        'Embarked': [0 if embarked.upper() == 'C' else 1 if embarked.upper() == 'Q' else 2],\n",
        "        'Title': [2],  # Asumimos Mr como default\n",
        "        'FamilySize': [sibsp + parch + 1],\n",
        "        'IsAlone': [1 if (sibsp + parch) == 0 else 0]\n",
        "    })\n",
        "\n",
        "    # Reordenar columnas para que coincidan con el entrenamiento\n",
        "    passenger_data = passenger_data[X.columns]\n",
        "\n",
        "    # Escalar\n",
        "    passenger_scaled = scaler.transform(passenger_data)\n",
        "\n",
        "    # Predecir\n",
        "    prediction = model.predict(passenger_scaled)\n",
        "    probability = model.predict_proba(passenger_scaled)[0][1]\n",
        "\n",
        "    resultado = \"SOBREVIVIRÍA\" if prediction[0] == 1 else \"NO SOBREVIVIRÍA\"\n",
        "    print(f\"\\nPredicción: El pasajero {resultado}\")\n",
        "    print(f\"Probabilidad de sobrevivir: {probability:.2%}\")\n",
        "\n",
        "# Ejecutar la función de predicción\n",
        "predecir_sobrevivencia()"
      ],
      "metadata": {
        "id": "lY8Q-M3qHWqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tZf4SuTRHZJ8"
      }
    }
  ]
}